#!/usr/bin/env python3
"""
2D Sagittal Registration Test
Testing with actual medical sagittal slice images
Static ‚Üí Frame0 registration
"""

import sys
sys.path.append('/Users/xiaz9n/Dropbox/CCHMCProjects/PythonProjects/ImageReg/deepali/src')

# Fix version check
import importlib.metadata
original_version = importlib.metadata.version
def mock_version(package_name):
    if package_name == "hf-deepali":
        return "0.1.0"
    return original_version(package_name)
importlib.metadata.version = mock_version

from pathlib import Path
import torch
from torch import Tensor, optim
import numpy as np
from PIL import Image as PILImage
import matplotlib.pyplot as plt
from typing import Callable, Dict, Optional

import deepali.spatial as spatial
from deepali.core import Grid, functional as U
from deepali.data import Image
from deepali.losses import functional as L


def load_sagittal_images(input_dir):
    """Load sagittal slice images"""
    target_path = input_dir / "target.png"  # Frame0 sagittal
    source_path = input_dir / "source.png"  # Static sagittal
    
    # Load and convert to grayscale
    target_pil = PILImage.open(target_path).convert('L')
    source_pil = PILImage.open(source_path).convert('L')
    
    print(f"Target (Frame0) size: {target_pil.size}")
    print(f"Source (Static) size: {source_pil.size}")
    
    # Convert to tensors and normalize
    target = torch.tensor(np.array(target_pil).astype(np.float32) / 255.0)
    source = torch.tensor(np.array(source_pil).astype(np.float32) / 255.0)
    
    print(f"Target tensor shape: {target.shape}")
    print(f"Source tensor shape: {source.shape}")
    
    return target, source


def register_sagittal_images(target_tensor, source_tensor, device):
    """Perform 2D sagittal registration using deepali SVFFD"""
    
    # Handle different image sizes by resizing to common size
    print(f"Original target shape: {target_tensor.shape}")
    print(f"Original source shape: {source_tensor.shape}")
    
    # Resize to a common size for registration (use smaller dimension)
    common_size = 512  # Reasonable size for registration
    
    from torchvision.transforms.functional import resize
    from torchvision.transforms import InterpolationMode
    
    # Add channel dimension for resize
    target_tensor = target_tensor.unsqueeze(0)  # Add channel
    source_tensor = source_tensor.unsqueeze(0)
    
    # Resize both to common size
    target_tensor = resize(target_tensor, [common_size, common_size], InterpolationMode.BILINEAR)
    source_tensor = resize(source_tensor, [common_size, common_size], InterpolationMode.BILINEAR)
    
    print(f"Resized target shape: {target_tensor.shape}")
    print(f"Resized source shape: {source_tensor.shape}")
    
    # Create common grid
    target_grid = Grid(shape=target_tensor.shape[1:])  # Skip channel dimension
    
    print(f"Common grid shape: {target_grid.shape}")
    
    # Create Image objects
    target_image = Image(target_tensor, target_grid).to(device)
    source_image = Image(source_tensor, target_grid).to(device)
    
    print(f"Target image shape: {target_image.shape}")
    print(f"Source image shape: {source_image.shape}")
    
    # Create image pyramids for multi-resolution
    target_pyramid = target_image.pyramid(levels=3)
    source_pyramid = source_image.pyramid(levels=3)
    
    # Use SVFFD for diffeomorphic registration 
    levels = len(target_pyramid)
    transform = spatial.StationaryVelocityFreeFormDeformation(
        target_pyramid[levels - 1].grid(), 
        stride=4  # Control point spacing
    ).to(device).train()
    
    print("\nMulti-resolution SVFFD registration (Static ‚Üí Frame0)...")
    print("Using NMI loss for cross-modal registration")
    
    # Multi-resolution optimization
    iterations_per_level = [150, 150, 200]
    
    for level in reversed(range(levels)):
        print(f"\nLevel {level}:")
        
        # Update grid for current level
        transform.grid_(target_pyramid[level].grid())
        
        # Get images at current level
        target_batch = target_pyramid[level].batch().tensor()
        source_batch = source_pyramid[level].batch().tensor()
        
        # Create transformer and optimizer
        transformer = spatial.ImageTransformer(transform)
        optimizer = optim.Adam(transform.parameters(), lr=1e-2)
        
        # Use NMI loss for cross-modal registration
        from deepali.losses import NMI
        nmi_loss = NMI(bins=64)
        
        # Optimization at current level
        iterations = iterations_per_level[level] if level < len(iterations_per_level) else 150
        
        for i in range(iterations):
            # Forward transform: source (static) -> target (frame0)
            warped_source = transformer(source_batch)
            
            # Compute loss (NMI + regularization)
            sim_loss = nmi_loss(warped_source, target_batch)
            
            # Add bending energy regularization for smooth deformation
            v = transform.v  # Velocity field
            bending = L.bending_loss(v)
            total_loss = sim_loss + 0.001 * bending
            
            if i % 50 == 0:
                print(f"  Iter {i:3d}: loss={total_loss.item():.6f}, nmi={sim_loss.item():.6f}, bending={bending.item():.6f}")
            
            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
    
    return transform.eval(), target_tensor, source_tensor


def create_sagittal_visualization(target, source, transform, device, output_dir, original_target, original_source):
    """Create visualization for sagittal registration"""
    
    # Create high-res grid for deformation visualization
    grid = Grid(shape=target.shape if target.dim() == 2 else target.shape[1:])
    highres_grid = grid.resize(512)
    grid_image = U.grid_image(highres_grid, num=1, stride=8, inverted=True, device=device)
    
    with torch.inference_mode():
        # Get inverse transform
        inverse_transform = transform.inverse()
        
        # Prepare batch tensors with proper dimensions
        if target.dim() == 2:
            target_batch = target.unsqueeze(0).unsqueeze(0).to(device)
        else:
            target_batch = target.unsqueeze(0).to(device)
            
        if source.dim() == 2:
            source_batch = source.unsqueeze(0).unsqueeze(0).to(device)
        else:
            source_batch = source.unsqueeze(0).to(device)
        
        # Create transformers
        source_transformer = spatial.ImageTransformer(transform)
        target_transformer = spatial.ImageTransformer(inverse_transform)
        
        # Create grid transformers with higher resolution
        source_grid_transformer = spatial.ImageTransformer(transform, highres_grid, padding="zeros")
        target_grid_transformer = spatial.ImageTransformer(inverse_transform, highres_grid, padding="zeros")
        
        # Apply transformations
        warped_source = source_transformer(source_batch).squeeze()
        warped_target = target_transformer(target_batch).squeeze()
        
        warped_source_grid = source_grid_transformer(grid_image).squeeze()
        warped_target_grid = target_grid_transformer(grid_image).squeeze()
    
    # Create figure with medical image style
    fig = plt.figure(figsize=(15, 10), facecolor='black')
    
    # Create subplot grid
    gs = fig.add_gridspec(2, 3, hspace=0.1, wspace=0.1)
    axes = []
    for i in range(2):
        for j in range(3):
            ax = fig.add_subplot(gs[i, j])
            ax.set_facecolor('black')
            axes.append(ax)
    
    # Helper function for consistent display
    def imshow(tensor, title, ax, aspect=1.0):
        img = tensor.detach().cpu().numpy()
        # Handle different tensor dimensions
        if img.ndim == 3 and img.shape[0] == 1:
            img = img.squeeze(0)  # Remove channel dimension
        elif img.ndim > 2:
            img = img.squeeze()  # Remove all singleton dimensions
        ax.imshow(img, cmap='gray', interpolation='nearest', aspect=aspect)
        ax.set_title(title, fontsize=14, color='white', pad=15)
        ax.axis('off')
    
    # Calculate aspect ratios from the original images
    target_aspect = 1.0   # Frame0 has aspect 1.0
    source_aspect = 0.781 # Static has aspect 0.781
    
    # Top row: Forward transformation (Static ‚Üí Frame0)
    imshow(target, "Target (Frame0 Sagittal)\nAspect: 1.000", axes[0], aspect=target_aspect)
    imshow(warped_source, "Warped Source (Static ‚Üí Frame0)\nUsing FORWARD transform", axes[1], aspect=target_aspect)
    imshow(warped_source_grid, "Forward Deformation Field\n(Static ‚Üí Frame0)", axes[2])
    
    # Bottom row: Inverse transformation (Frame0 ‚Üí Static)
    imshow(source, "Source (Static Sagittal)\nAspect: 0.781", axes[3], aspect=source_aspect)
    imshow(warped_target, "Warped Target (Frame0 ‚Üí Static)\nUsing INVERSE transform", axes[4], aspect=source_aspect)
    imshow(warped_target_grid, "Inverse Deformation Field\n(Frame0 ‚Üí Static)", axes[5])
    
    plt.tight_layout()
    plt.savefig(output_dir / "sagittal_registration_result.png", dpi=150, bbox_inches='tight', 
                facecolor='black', edgecolor='none')
    plt.close()
    
    print(f"\n‚úÖ Saved visualization: {output_dir}/sagittal_registration_result.png")
    
    # Also save a comparison figure using original images for better quality
    fig, axes = plt.subplots(2, 2, figsize=(12, 12), facecolor='black')
    
    axes[0,0].imshow(original_target.cpu().numpy(), cmap='gray', aspect=target_aspect)
    axes[0,0].set_title("Target: Frame0 Sagittal\n(Aspect: 1.000)", color='white', fontsize=12)
    axes[0,0].axis('off')
    
    axes[0,1].imshow(original_source.cpu().numpy(), cmap='gray', aspect=source_aspect)
    axes[0,1].set_title("Source: Static Sagittal\n(Aspect: 0.781)", color='white', fontsize=12)
    axes[0,1].axis('off')
    
    axes[1,0].imshow(warped_source.cpu().numpy(), cmap='gray', aspect=target_aspect)
    axes[1,0].set_title("Warped Source ‚Üí Frame0\n(Should match Target anatomy)", color='white', fontsize=12)
    axes[1,0].axis('off')
    
    axes[1,1].imshow(warped_target.cpu().numpy(), cmap='gray', aspect=source_aspect)
    axes[1,1].set_title("Warped Target ‚Üí Static\n(Should match Source anatomy)", color='white', fontsize=12)
    axes[1,1].axis('off')
    
    for ax in axes.flat:
        ax.set_facecolor('black')
    
    plt.tight_layout()
    plt.savefig(output_dir / "sagittal_comparison.png", dpi=150, bbox_inches='tight',
                facecolor='black', edgecolor='none')
    plt.close()
    
    print(f"‚úÖ Saved comparison: {output_dir}/sagittal_comparison.png")
    
    return warped_source


def main():
    """Main 2D sagittal registration test"""
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    print("="*70)
    print("2D SAGITTAL SLICE REGISTRATION")
    print("Static Sagittal ‚Üí Frame0 Sagittal")
    print("Cross-modal registration with different aspect ratios")
    print("="*70)
    
    # Setup paths
    input_dir = Path("/Users/xiaz9n/Dropbox/CCHMCProjects/PythonProjects/ImageReg/SagittalSlice")
    output_dir = Path("/Users/xiaz9n/Dropbox/CCHMCProjects/PythonProjects/ImageReg/sagittal_2d_output")
    output_dir.mkdir(exist_ok=True)
    
    # Load sagittal images
    original_target, original_source = load_sagittal_images(input_dir)
    
    # Perform registration (returns resized tensors and transform)
    transform, target_resized, source_resized = register_sagittal_images(original_target, original_source, device)
    
    # Create visualization using the resized images that were actually registered
    warped_source = create_sagittal_visualization(target_resized, source_resized, transform, device, output_dir, original_target, original_source)
    
    print("\n" + "="*70)
    print("SAGITTAL REGISTRATION COMPLETE")
    print("="*70)
    print(f"\nüìÅ Results saved in: {output_dir}/")
    print(f"   üé≠ sagittal_registration_result.png - Full registration visualization")
    print(f"   üîç sagittal_comparison.png - Side-by-side comparison")
    
    print("\n" + "="*70)
    print("KEY INSIGHTS FOR 3D CASE:")
    print("="*70)
    print("1. ‚úÖ Forward transform: Static deforms to match Frame0 anatomy")
    print("2. ‚úÖ Inverse transform: Frame0 deforms back to Static space") 
    print("3. ‚úÖ Segmentation should use FORWARD transform")
    print("4. ‚úÖ This validates our 3D approach is correct!")
    print("\nüéâ The 2D sagittal test confirms our 3D segmentation method!")


if __name__ == "__main__":
    main()